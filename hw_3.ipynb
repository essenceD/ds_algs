{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 *. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.<br>\n",
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.<br>\n",
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).<br>\n",
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).<br>\n",
    "5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.<br>\n",
    "6. Могла ли модель переобучиться? Почему?<br>\n",
    "7 *. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x_std):\n",
    "    res = (x_std - x_std.mean()) / x_std.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 *. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n",
    "def calc_logloss(y_log, y_pred_log):\n",
    "    mask = 1e-10\n",
    "    y_pred_log[y_pred_log == 0] = mask\n",
    "    y_pred_log[y_pred_log == 1] = 1 - mask\n",
    "    err = - np.mean(y_log * np.log(y_pred_log) + (1.0 - y_log) * np.log(1.0 - y_pred_log))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z_sig):\n",
    "    res = 1 / (1 + np.exp(-z_sig))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X_em, y_em, iterations, alpha=1e-4, metric: callable = None):\n",
    "    np.random.seed(42)\n",
    "    W_em = np.random.randn(X_em.shape[0])\n",
    "    n = X_em.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z_em = np.dot(W_em, X_em)\n",
    "        y_pred_em = sigmoid(z_em)\n",
    "        err_em = calc_logloss(y_em, y_pred_em)\n",
    "        W_em -= alpha * (1/n * np.dot((y_pred_em - y_em), X_em.T))\n",
    "    return [err_em, W_em]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70, 236), (30, 236), (70,), (30,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.make_classification(n_samples=100, n_features=236\n",
    "                                       , n_informative=23,\n",
    "                                       n_redundant=0, n_classes=2, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "def get_params_for_min_logloss(X_gpml, y_gpml, iters: list, alfa: list) -> list:\n",
    "    result = {}\n",
    "    for cicle in iters:\n",
    "        for speed in alfa:\n",
    "            result[f'{cicle}:{speed}'] = eval_model(X_gpml, y_gpml, cicle, alpha=speed)\n",
    "    return [min(result, key=result.get), result[min(result, key=result.get)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "n_iterations: 1000000\n",
      "learning_rate: 0.001\n",
      "log_loss: 0.000150\n",
      "weights:\n",
      "[ 4.38365836e-01  1.47858565e-01 -2.71881075e-01  1.37474371e+00\n",
      "  7.72176385e-02 -5.80753799e-01  1.46285935e+00  5.32556006e-02\n",
      " -2.89951935e-01  3.28341228e-01 -8.25738154e-01  4.99080892e-01\n",
      "  5.56081527e-01 -1.48662651e+00 -1.36760980e+00 -6.46133447e-01\n",
      " -6.56806415e-01  5.36677553e-01 -1.04107476e+00 -1.54300150e+00\n",
      "  7.74445106e-01 -4.46090730e-01  3.48742691e-01 -1.18923553e+00\n",
      "  9.14807283e-02 -7.59720336e-01 -1.24105710e-01  3.07151332e-01\n",
      " -6.58853966e-01 -7.91274656e-01 -9.20243421e-01  1.63743836e+00\n",
      " -3.91808060e-01 -5.54565447e-01  7.89934649e-01 -1.11764942e+00\n",
      "  7.23217961e-01 -1.89885970e+00 -1.12661380e+00  7.94391572e-01\n",
      "  9.98227786e-01  2.27008043e-03 -2.93107412e-01  1.61171848e-01\n",
      " -2.84931105e+00  2.28938768e-01 -7.61711895e-01  9.06821353e-01\n",
      "  4.42774253e-01 -1.09918672e+00  5.59764081e-01 -4.35627878e-01\n",
      " -1.04130786e+00  8.61109067e-01  8.82953463e-01  4.95647059e-01\n",
      " -1.66559103e+00 -9.40831388e-01  3.75034159e-01  1.21458909e+00\n",
      " -4.75742439e-01 -1.01413927e-01 -8.57634794e-01 -1.68921955e+00\n",
      "  7.67767659e-01  1.47589053e+00  2.89761742e-01  8.28122981e-01\n",
      " -3.36354875e-01 -2.68710458e-02  1.60155022e-01  1.16247170e+00\n",
      "  5.23844619e-01  2.35116587e+00 -2.04510967e+00  4.33673347e-01\n",
      " -3.24023239e-03  6.61985535e-02 -3.75283374e-01 -2.75368494e+00\n",
      " -8.61032036e-01  1.31034933e+00  8.10775496e-01 -4.01507144e-01\n",
      " -1.10354551e+00 -8.90499744e-01  8.81267276e-01 -4.10230330e-01\n",
      " -1.42994804e-02 -1.88153512e-01 -1.15059546e-01  9.23539117e-01\n",
      " -5.04392444e-01 -7.71704867e-01 -5.07218519e-01 -8.52280077e-01\n",
      "  7.01323212e-01  5.21768715e-01 -2.05353760e-01  1.21002477e-01\n",
      " -1.50446634e+00  5.90699599e-01 -2.82461843e-01 -1.37017595e+00\n",
      " -7.06619257e-01  5.18230829e-01  1.70825294e+00  9.55293882e-01\n",
      " -1.29195742e-02  1.74980604e-01 -2.00663790e+00  2.33040511e-01\n",
      "  2.06074302e-01  2.06645413e+00 -1.48530555e-01 -2.30826034e-01\n",
      " -7.60539039e-01 -6.24625575e-01  5.52040800e-01  4.86463095e-01\n",
      " -4.65800059e-01 -5.64295121e-01  5.81500752e-01 -1.62836819e+00\n",
      "  1.03979345e+00  1.12189364e+00 -8.07149631e-01 -1.13905948e+00\n",
      " -1.57031688e-01 -7.18559622e-01 -9.81358403e-01  5.65687923e-01\n",
      " -1.33476580e+00 -9.42172411e-01 -5.81393735e-01  1.44064428e+00\n",
      "  7.25303410e-03 -1.04183184e+00  2.40530046e-01 -1.29307615e+00\n",
      "  1.47541258e+00  1.74670324e+00 -1.67703420e+00 -2.85974614e-01\n",
      "  4.49270159e-01  9.32462627e-02 -1.27380010e+00 -6.26719229e-01\n",
      "  6.54567044e-01  2.27237427e-01  4.86292791e-01  2.13519814e-01\n",
      " -1.01570741e+00  2.59435849e-01  3.93691293e-01 -5.28291446e-01\n",
      "  9.43306273e-01 -6.56543661e-02 -1.26006973e+00  3.06723720e-01\n",
      " -6.83501478e-01  5.93465381e-01  1.17797872e+00 -5.53761325e-01\n",
      "  4.83460007e-01  5.34491903e-01  6.59699528e-01 -2.03274840e-01\n",
      " -4.03311814e-01 -4.62150859e-01 -7.24816292e-01 -6.41162451e-01\n",
      "  3.70298265e-01  1.83847891e-01  8.02377088e-02  8.26075457e-01\n",
      " -1.92800363e-01  1.02386649e+00  1.32308427e-01  2.85070337e+00\n",
      "  7.30941365e-01 -7.50166789e-02  3.59369308e-01 -3.34069301e-03\n",
      " -2.71291177e-01  2.12523356e-01 -4.30993800e-01 -1.70143128e-01\n",
      " -6.16193649e-01 -4.98536553e-01 -1.50548844e+00  1.63645338e-01\n",
      "  6.92412204e-02 -9.10936219e-01  5.20447978e-01  2.82117895e-01\n",
      " -7.43917584e-01  6.86546793e-02 -7.27723097e-02 -1.46266880e+00\n",
      "  3.94950269e-02  1.11351790e+00  5.30343438e-02  9.03228206e-01\n",
      " -1.59034464e+00 -6.26231562e-01  4.29298200e-01  7.14551543e-01\n",
      "  9.15639397e-01  3.58538709e+00  5.31215691e-01  9.26185701e-01\n",
      "  7.31450406e-01  6.27848642e-01  1.31521855e-01  2.53756086e-03\n",
      " -5.28675302e-01 -3.14484095e-01 -3.68431731e-01 -1.21350847e-01\n",
      "  3.14345710e-01 -2.05445580e+00 -1.22105778e-01 -8.11376561e-01\n",
      " -2.44716336e-01  1.52287230e+00 -6.70968327e-02 -1.05181843e+00\n",
      " -7.38354759e-01  4.07664636e-01 -5.52439575e-01 -1.13544932e-01\n",
      " -4.32307983e-02 -8.59891981e-01  2.35936165e+00  9.01011528e-01]\n"
     ]
    }
   ],
   "source": [
    "iter_list = [10 ** i for i in range(3, 7)]\n",
    "alfa_list = [10 ** -i for i in range(3, 8)]\n",
    "\n",
    "params = get_params_for_min_logloss(X_train.T, y_train, iter_list, alfa_list)\n",
    "\n",
    "best_iters, best_lr = int(params[0].split(':')[0]), float(params[0].split(':')[1])\n",
    "err, W = params[1][0], params[1][1]\n",
    "print(f'Best params:\\nn_iterations: {best_iters}\\nlearning_rate: {best_lr}\\nlog_loss: {err:.6f}\\nweights:\\n{W}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 \n",
    "#(на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "def calc_pred_proba(W_pp: np.array, X_pp:np.array) -> np.array:\n",
    "    return sigmoid(np.dot(W_pp.T, X_pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89319014e-29, 2.60806967e-22, 9.99898031e-01, 3.03148931e-04,\n",
       "       9.99655940e-01, 1.11811834e-11, 9.99692472e-01, 9.99569640e-01,\n",
       "       6.18382376e-05, 1.17634338e-10, 5.80869133e-09, 2.95349488e-10,\n",
       "       9.99669921e-01, 1.00000000e+00, 1.87245767e-04, 9.99999996e-01,\n",
       "       9.99669545e-01, 1.00000000e+00, 9.99775211e-01, 1.45798564e-10,\n",
       "       9.99680507e-01, 1.81519477e-04, 3.90007024e-09, 8.09773243e-05,\n",
       "       9.99864067e-01, 3.23783436e-04, 9.99737813e-01, 9.99966031e-01,\n",
       "       1.00000000e+00, 9.99645796e-01, 8.86679951e-12, 4.28515529e-14,\n",
       "       3.19612383e-11, 9.99745054e-01, 9.99999451e-01, 1.00000000e+00,\n",
       "       1.56583160e-12, 4.26761427e-05, 4.11150696e-08, 1.57578156e-04,\n",
       "       9.99935694e-01, 5.61860329e-06, 9.99668690e-01, 4.35323903e-04,\n",
       "       3.71403479e-04, 1.00000000e+00, 9.99653232e-01, 2.24773476e-04,\n",
       "       5.00048762e-15, 3.70217520e-04, 4.02039325e-04, 2.19855687e-15,\n",
       "       2.90319493e-04, 1.34594567e-17, 1.31601224e-05, 9.99615207e-01,\n",
       "       3.65487991e-04, 1.24511660e-04, 9.99561945e-01, 3.89198071e-04,\n",
       "       2.77362853e-13, 9.99720734e-01, 9.99750829e-01, 9.99999099e-01,\n",
       "       9.99996623e-01, 9.99742601e-01, 9.99991366e-01, 5.95721978e-06,\n",
       "       1.16830942e-04, 9.99770461e-01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_proba = calc_pred_proba(W, X_train.T)\n",
    "y_train_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n",
    "def calc_pred(W_cp: np.array, X_cp: np.array) -> np.array:\n",
    "    y_pred_cp = np.zeros((1, X_cp.shape[1]))\n",
    "    W_cp = W_cp.reshape(X_cp.shape[0], 1)\n",
    "    prob_pred_cp = sigmoid(np.dot(W_cp.T, X_cp))\n",
    "    \n",
    "    border_cp = prob_pred_cp.mean() * (y_train[y_train == 1].shape[0] / y_train[y_train == 0].shape[0]) # сдвинул границу отбора с учетом неравномерности распределения целевой переменной\n",
    "    \n",
    "    for prob in range(prob_pred_cp.shape[1]):\n",
    "        if prob_pred_cp[:, prob] > border_cp:\n",
    "            y_pred_cp[:, prob] = 1\n",
    "        else:\n",
    "            y_pred_cp[:, prob] = 0\n",
    "    return y_pred_cp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = calc_pred(W, X_train.T)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_proba = calc_pred_proba(W, X_test.T)\n",
    "y_pred_test = calc_pred(W, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n",
    "def calc_accuracy(predictions_ca: np.array, target_ca: np.array) -> float:\n",
    "    return (100.0 - np.mean(np.abs(predictions_ca - target_ca) * 100.0))\n",
    "\n",
    "def calc_error_matrix(predictions_cem: np.array, target_cem: np.array) -> np.array:\n",
    "    ans = np.array([\n",
    "        np.array([predictions_cem[(predictions_cem == 1) & (target_cem == 1)].shape[0], predictions_cem[(predictions_cem == 1) & (target_cem == 0)].shape[0]]),\n",
    "        np.array([predictions_cem[(predictions_cem == 0) & (target_cem == 1)].shape[0], predictions_cem[(predictions_cem == 0) & (target_cem == 0)].shape[0]])\n",
    "    ])\n",
    "    return ans\n",
    "\n",
    "def calc_precision(error_matrix_cp: np.array) -> float:\n",
    "    return error_matrix_cp[0][0] / (error_matrix_cp[0][0] + error_matrix_cp[0][1])\n",
    "\n",
    "def calc_recall(error_matrix_cr: np.array) -> float:\n",
    "    return error_matrix_cr[0][0] / (error_matrix_cr[0][0] + error_matrix_cr[1][0])\n",
    "\n",
    "def calc_f1(error_matrix_cf: np.array) -> float:\n",
    "    p = calc_precision(error_matrix_cf)\n",
    "    r = calc_recall(error_matrix_cf)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_accuracy: 100.0\t\t\tTest_accuracy: 63.3333\n",
      "Train_precision: 1.0000\t\t\tTest_precision: 0.6875\n",
      "Train_recall: 1.0000\t\t\tTest_recall: 0.6471\n",
      "Train_f1_score: 1.0000\t\t\tTest_f1_score: 0.6667\n",
      "Train_error_matrix:\t\t\tTest_error_matrix:\n",
      "[32  0]\t\t\t\t\t[11  5]\n",
      "[ 0 38]\t\t\t\t\t[6 8]\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = calc_accuracy(y_pred_train, y_train)\n",
    "accuracy_test = calc_accuracy(y_pred_test, y_test)\n",
    "\n",
    "error_matrix_train = calc_error_matrix(y_pred_train, y_train)\n",
    "error_matrix_test = calc_error_matrix(y_pred_test, y_test)\n",
    "\n",
    "precision_train = calc_precision(error_matrix_train)\n",
    "precision_test = calc_precision(error_matrix_test)\n",
    "\n",
    "recall_train = calc_recall(error_matrix_train)\n",
    "recall_test = calc_recall(error_matrix_test)\n",
    "\n",
    "f1_score_train = calc_f1(error_matrix_train)\n",
    "f1_score_test = calc_f1(error_matrix_test)\n",
    "\n",
    "print(f'Train_accuracy: {accuracy_train}\\t\\t\\tTest_accuracy: {accuracy_test:.4f}\\nTrain_precision: {precision_train:.4f}\\t\\t\\tTest_precision: {precision_test:.4f}\\nTrain_recall: {recall_train:.4f}\\t\\t\\tTest_recall: {recall_test:.4f}\\nTrain_f1_score: {f1_score_train:.4f}\\t\\t\\tTest_f1_score: {f1_score_test:.4f}\\nTrain_error_matrix:\\t\\t\\tTest_error_matrix:\\n{error_matrix_train[0]}\\t\\t\\t\\t\\t{error_matrix_test[0]}\\n{error_matrix_train[1]}\\t\\t\\t\\t\\t{error_matrix_test[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего модель переобучилась, потому что слишком большая разница в метрике accuracy. Изначально было на тесте 0.6, но я подправил границы отбора принадлежности к классу с учетом распределения тренировочных классов и стало немного лучше. Думаю, что это случилось потому, что:\n",
    "- было использовано недостаточно гиперпараметров;\n",
    "- Мы добивались минимизации logloss, что потянуло за собой большое количество эпох обучения. Было бы их меньше - точность на трейне была бы меньше, а на тесте - больше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 *. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно.\n",
    "def eval_model_l1(X_em1, y_em1, iterations, alpha=1e-4, metric: callable = None, lamda=1e-5):\n",
    "    np.random.seed(42)\n",
    "    W_em1 = np.random.randn(X_em1.shape[0])\n",
    "    n = X_em1.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z_em1 = np.dot(W_em1, X_em1)\n",
    "        y_pred_em1 = sigmoid(z_em1)\n",
    "        err_em1 = calc_logloss(y_em1, y_pred_em1)\n",
    "        W_em1 -= alpha * (1/n * np.dot((y_pred_em1 - y_em1), X_em1.T)) / n + lamda * np.linalg.norm(W_em1, ord=1)\n",
    "    return W_em1\n",
    "\n",
    "def eval_model_l2(X_em2, y_em2, iterations, alpha=1e-4, metric: callable = None, lamda=1e-5):\n",
    "    np.random.seed(42)\n",
    "    W_em2 = np.random.randn(X_em2.shape[0])\n",
    "    n = X_em2.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z_em2 = np.dot(W_em2, X_em2)\n",
    "        y_pred_em2 = sigmoid(z_em2)\n",
    "        err_em2 = calc_logloss(y_em2, y_pred_em2)\n",
    "        W_em2 -= alpha * (1/n * np.dot((y_pred_em2 - y_em2), X_em2.T)) / n + lamda * np.linalg.norm(W_em2, ord=2)\n",
    "    return W_em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n",
      "C:\\Users\\EssenceD\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:2557: RuntimeWarning: overflow encountered in reduce\n",
      "  return add.reduce(abs(x), axis=axis, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "W_l1 = eval_model_l1(X_train.T, y_train, best_iters, best_lr)\n",
    "W_l2 = eval_model_l2(X_train.T, y_train, best_iters, best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_l1 = calc_pred(W_l1, X_train.T)\n",
    "y_pred_train_l2 = calc_pred(W_l2, X_train.T)\n",
    "\n",
    "y_pred_test_l1 = calc_pred(W_l1, X_test.T)\n",
    "y_pred_test_l2 = calc_pred(W_l2, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-c5dbe1643090>:13: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  return error_matrix_cp[0][0] / (error_matrix_cp[0][0] + error_matrix_cp[0][1])\n"
     ]
    }
   ],
   "source": [
    "accuracy_train_l1 = calc_accuracy(y_pred_train_l1, y_train)\n",
    "accuracy_test_l1 = calc_accuracy(y_pred_test_l1, y_test)\n",
    "accuracy_train_l2 = calc_accuracy(y_pred_train_l2, y_train)\n",
    "accuracy_test_l2 = calc_accuracy(y_pred_test_l2, y_test)\n",
    "\n",
    "error_matrix_train_l1 = calc_error_matrix(y_pred_train_l1, y_train)\n",
    "error_matrix_test_l1 = calc_error_matrix(y_pred_test_l1, y_test)\n",
    "error_matrix_train_l2 = calc_error_matrix(y_pred_train_l2, y_train)\n",
    "error_matrix_test_l2 = calc_error_matrix(y_pred_test_l2, y_test)\n",
    "\n",
    "precision_train_l1 = calc_precision(error_matrix_train_l1)\n",
    "precision_test_l1 = calc_precision(error_matrix_test_l1)\n",
    "precision_train_l2 = calc_precision(error_matrix_train_l2)\n",
    "precision_test_l2 = calc_precision(error_matrix_test_l2)\n",
    "\n",
    "recall_train_l1 = calc_recall(error_matrix_train_l1)\n",
    "recall_test_l1 = calc_recall(error_matrix_test_l1)\n",
    "recall_train_l2 = calc_recall(error_matrix_train_l2)\n",
    "recall_test_l2 = calc_recall(error_matrix_test_l2)\n",
    "\n",
    "f1_score_train_l1 = calc_f1(error_matrix_train_l1)\n",
    "f1_score_test_l1 = calc_f1(error_matrix_test_l1)\n",
    "f1_score_train_l2 = calc_f1(error_matrix_train_l2)\n",
    "f1_score_test_l2 = calc_f1(error_matrix_test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_acc: 100.0\t\tTest_acc: 63.3333\t\tTrain_L1_acc: 54.2857\t\tTest_L1_acc: 43.3333\t\tTrain_L2_acc: 50.0000\t\tTest_L2_acc: 53.3333\n",
      "\n",
      "Train_prec: 1.0000\t\tTest_prec: 0.6875\t\tTrain_L1_prec: nan\t\tTest_L1_prec: nan\t\tTrain_L2_prec: 0.4615\t\tTest_L2_prec: 0.6154\n",
      "\n",
      "Train_rec: 1.0000\t\tTest_rec: 0.6471\t\tTrain_L1_rec: 0.0000\t\tTest_L1_rec: 0.0000\t\tTrain_L2_rec: 0.5625\t\tTest_L2_rec: 0.4706\n",
      "\n",
      "Train_f1: 1.0000\t\tTest_f1: 0.6667\t\t\tTrain_L1_f1: nan\t\tTest_L1_f1: nan\t\t\tTrain_L2_f1: 0.5070\t\tTest_L2_f1: 0.5333\n",
      "\n",
      "Train_err_mat:\t\tTest_err_mat:\t\t\tTrain_L1_err_mat:\t\tTest_L1_err_mat:\t\tTrain_L2_err_mat:\t\tTest_L2_err_mat:\n",
      "[32  0]\t\t\t\t[11  5]\t\t\t\t[0 0]\t\t\t\t[0 0]\t\t\t\t[18 21]\t\t\t\t[8 5]\n",
      "[ 0 38]\t\t\t\t[6 8]\t\t\t\t[32 38]\t\t\t\t[17 13]\t\t\t\t[14 17]\t\t\t\t[9 8]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train_acc: {accuracy_train}\\t\\tTest_acc: {accuracy_test:.4f}\\t\\tTrain_L1_acc: {accuracy_train_l1:.4f}\\t\\tTest_L1_acc: {accuracy_test_l1:.4f}\\t\\tTrain_L2_acc: {accuracy_train_l2:.4f}\\t\\tTest_L2_acc: {accuracy_test_l2:.4f}\\n\\nTrain_prec: {precision_train:.4f}\\t\\tTest_prec: {precision_test:.4f}\\t\\tTrain_L1_prec: {precision_train_l1:.4f}\\t\\tTest_L1_prec: {precision_test_l1:.4f}\\t\\tTrain_L2_prec: {precision_train_l2:.4f}\\t\\tTest_L2_prec: {precision_test_l2:.4f}\\n\\nTrain_rec: {recall_train:.4f}\\t\\tTest_rec: {recall_test:.4f}\\t\\tTrain_L1_rec: {recall_train_l1:.4f}\\t\\tTest_L1_rec: {recall_test_l1:.4f}\\t\\tTrain_L2_rec: {recall_train_l2:.4f}\\t\\tTest_L2_rec: {recall_test_l2:.4f}\\n\\nTrain_f1: {f1_score_train:.4f}\\t\\tTest_f1: {f1_score_test:.4f}\\t\\t\\tTrain_L1_f1: {f1_score_train_l1:.4f}\\t\\tTest_L1_f1: {f1_score_test_l1:.4f}\\t\\t\\tTrain_L2_f1: {f1_score_train_l2:.4f}\\t\\tTest_L2_f1: {f1_score_test_l2:.4f}\\n\\nTrain_err_mat:\\t\\tTest_err_mat:\\t\\t\\tTrain_L1_err_mat:\\t\\tTest_L1_err_mat:\\t\\tTrain_L2_err_mat:\\t\\tTest_L2_err_mat:\\n{error_matrix_train[0]}\\t\\t\\t\\t{error_matrix_test[0]}\\t\\t\\t\\t{error_matrix_train_l1[0]}\\t\\t\\t\\t{error_matrix_test_l1[0]}\\t\\t\\t\\t{error_matrix_train_l2[0]}\\t\\t\\t\\t{error_matrix_test_l2[0]}\\n{error_matrix_train[1]}\\t\\t\\t\\t{error_matrix_test[1]}\\t\\t\\t\\t{error_matrix_train_l1[1]}\\t\\t\\t\\t{error_matrix_test_l1[1]}\\t\\t\\t\\t{error_matrix_train_l2[1]}\\t\\t\\t\\t{error_matrix_test_l2[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из ответа, L1 регуляризация заставляет модель предсказывать только нулевой класс, из-за чего имеем ошибку в precision, recall и f1_score. Регуляризация L2 дала слишком большие штрафы, поэтому общая точность моджели на уровне случайного гадания (как вариант для улучшения - уменьшить количество итераций в подборе весов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    }
   ],
   "source": [
    "# Просто ради интереса что будет. Количество эпох и скорость обучения взял из головы.\n",
    "W2_train = eval_model(X_train.T, y_train, 50000, 1e-5)[1]\n",
    "W2_l1 = eval_model_l1(X_train.T, y_train, 50000, 1e-5)\n",
    "W2_l2 = eval_model_l2(X_train.T, y_train, 50000, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    }
   ],
   "source": [
    "y2_pred_train = calc_pred(W2_train, X_train.T)\n",
    "y2_pred_test = calc_pred(W2_train, X_test.T)\n",
    "y2_pred_train_l1 = calc_pred(W2_l1, X_train.T)\n",
    "y2_pred_test_l1 = calc_pred(W2_l1, X_test.T)\n",
    "y2_pred_train_l2 = calc_pred(W2_l2, X_train.T)\n",
    "y2_pred_test_l2 = calc_pred(W2_l2, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train2 = calc_accuracy(y2_pred_train, y_train)\n",
    "accuracy_test2 = calc_accuracy(y2_pred_test, y_test)\n",
    "accuracy_train_l12 = calc_accuracy(y2_pred_train_l1, y_train)\n",
    "accuracy_test_l12 = calc_accuracy(y2_pred_test_l1, y_test)\n",
    "accuracy_train_l22 = calc_accuracy(y2_pred_train_l2, y_train)\n",
    "accuracy_test_l22 = calc_accuracy(y2_pred_test_l2, y_test)\n",
    "\n",
    "error_matrix_train2 = calc_error_matrix(y2_pred_train, y_train)\n",
    "error_matrix_test2 = calc_error_matrix(y2_pred_test, y_test)\n",
    "error_matrix_train_l12 = calc_error_matrix(y2_pred_train_l1, y_train)\n",
    "error_matrix_test_l12 = calc_error_matrix(y2_pred_test_l1, y_test)\n",
    "error_matrix_train_l22 = calc_error_matrix(y2_pred_train_l2, y_train)\n",
    "error_matrix_test_l22 = calc_error_matrix(y2_pred_test_l2, y_test)\n",
    "\n",
    "\n",
    "precision_train2 = calc_precision(error_matrix_train2)\n",
    "precision_test2 = calc_precision(error_matrix_test2)\n",
    "precision_train_l12 = calc_precision(error_matrix_train_l12)\n",
    "precision_test_l12 = calc_precision(error_matrix_test_l12)\n",
    "precision_train_l22 = calc_precision(error_matrix_train_l22)\n",
    "precision_test_l22 = calc_precision(error_matrix_test_l22)\n",
    "\n",
    "recall_train2 = calc_recall(error_matrix_train2)\n",
    "recall_test2 = calc_recall(error_matrix_test2)\n",
    "recall_train_l12 = calc_recall(error_matrix_train_l12)\n",
    "recall_test_l12 = calc_recall(error_matrix_test_l12)\n",
    "recall_train_l22 = calc_recall(error_matrix_train_l22)\n",
    "recall_test_l22 = calc_recall(error_matrix_test_l22)\n",
    "\n",
    "f1_score_train2 = calc_f1(error_matrix_train2)\n",
    "f1_score_test2 = calc_f1(error_matrix_test2)\n",
    "f1_score_train_l12 = calc_f1(error_matrix_train_l12)\n",
    "f1_score_test_l12 = calc_f1(error_matrix_test_l12)\n",
    "f1_score_train_l22 = calc_f1(error_matrix_train_l22)\n",
    "f1_score_test_l22 = calc_f1(error_matrix_test_l22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_acc: 51.4286\t\tTest_acc: 50.0000\t\tTrain_L1_acc: 50.0000\t\tTest_L1_acc: 53.3333\t\tTrain_L2_acc: 48.5714\t\tTest_L2_acc: 53.3333\n",
      "\n",
      "Train_prec: 0.4722\t\tTest_prec: 0.5714\t\tTrain_L1_prec: 0.4615\t\tTest_L1_prec: 0.6154\t\tTrain_L2_prec: 0.4474\t\tTest_L2_prec: 0.6154\n",
      "\n",
      "Train_rec: 0.5312\t\tTest_rec: 0.4706\t\tTrain_L1_rec: 0.5625\t\tTest_L1_rec: 0.4706\t\tTrain_L2_rec: 0.5312\t\tTest_L2_rec: 0.4706\n",
      "\n",
      "Train_f1: 0.5000\t\tTest_f1: 0.5161\t\t\tTrain_L1_f1: 0.5070\t\tTest_L1_f1: 0.5333\t\tTrain_L2_f1: 0.4857\t\tTest_L2_f1: 0.5333\n",
      "\n",
      "Train_err_mat:\t\tTest_err_mat:\t\t\tTrain_L1_err_mat:\t\tTest_L1_err_mat:\t\tTrain_L2_err_mat:\t\tTest_L2_err_mat:\n",
      "[17 19]\t\t\t\t[8 6]\t\t\t\t[18 21]\t\t\t\t[8 5]\t\t\t\t[17 21]\t\t\t\t[8 5]\n",
      "[15 19]\t\t\t\t[9 7]\t\t\t\t[14 17]\t\t\t\t[9 8]\t\t\t\t[15 17]\t\t\t\t[9 8]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train_acc: {accuracy_train2:.4f}\\t\\tTest_acc: {accuracy_test2:.4f}\\t\\tTrain_L1_acc: {accuracy_train_l12:.4f}\\t\\tTest_L1_acc: {accuracy_test_l12:.4f}\\t\\tTrain_L2_acc: {accuracy_train_l22:.4f}\\t\\tTest_L2_acc: {accuracy_test_l22:.4f}\\n\\nTrain_prec: {precision_train2:.4f}\\t\\tTest_prec: {precision_test2:.4f}\\t\\tTrain_L1_prec: {precision_train_l12:.4f}\\t\\tTest_L1_prec: {precision_test_l12:.4f}\\t\\tTrain_L2_prec: {precision_train_l22:.4f}\\t\\tTest_L2_prec: {precision_test_l22:.4f}\\n\\nTrain_rec: {recall_train2:.4f}\\t\\tTest_rec: {recall_test2:.4f}\\t\\tTrain_L1_rec: {recall_train_l12:.4f}\\t\\tTest_L1_rec: {recall_test_l12:.4f}\\t\\tTrain_L2_rec: {recall_train_l22:.4f}\\t\\tTest_L2_rec: {recall_test_l22:.4f}\\n\\nTrain_f1: {f1_score_train2:.4f}\\t\\tTest_f1: {f1_score_test2:.4f}\\t\\t\\tTrain_L1_f1: {f1_score_train_l12:.4f}\\t\\tTest_L1_f1: {f1_score_test_l12:.4f}\\t\\tTrain_L2_f1: {f1_score_train_l22:.4f}\\t\\tTest_L2_f1: {f1_score_test_l22:.4f}\\n\\nTrain_err_mat:\\t\\tTest_err_mat:\\t\\t\\tTrain_L1_err_mat:\\t\\tTest_L1_err_mat:\\t\\tTrain_L2_err_mat:\\t\\tTest_L2_err_mat:\\n{error_matrix_train2[0]}\\t\\t\\t\\t{error_matrix_test2[0]}\\t\\t\\t\\t{error_matrix_train_l12[0]}\\t\\t\\t\\t{error_matrix_test_l12[0]}\\t\\t\\t\\t{error_matrix_train_l22[0]}\\t\\t\\t\\t{error_matrix_test_l22[0]}\\n{error_matrix_train2[1]}\\t\\t\\t\\t{error_matrix_test2[1]}\\t\\t\\t\\t{error_matrix_train_l12[1]}\\t\\t\\t\\t{error_matrix_test_l12[1]}\\t\\t\\t\\t{error_matrix_train_l22[1]}\\t\\t\\t\\t{error_matrix_test_l22[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из результатов (лучшая accuracy), секрет хорошей модели логистической регрессии связан не с минимальной logloss, а с уменьшением скорости обучения и недопусканием переобучения модели. С новыми параметрами модели L1 регуляризация получила смысл и перестала предсказывать нули, что тоже порадовало. Но все-таки данная модель недообучилась. Это следует из того, что на тренировочном датасете мы получили точность меньше, чем на тестовом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К дз это не относится, но попробуем реализовать функция поиска гиперпараметров для максимизации точности предсказаний..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(sample: dict, search) -> str:\n",
    "    return [key for key, value in sample.items() if value == search][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_score(sample: list) -> list:\n",
    "    return  max(sorted(sample, key=lambda i: i[1]), key=lambda i: i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_max_acc(data_gpma: np.array, target_gpma: np.array, iter_gpma: list, lr_gpma: list) -> dict:\n",
    "    X_train_gpma, X_test_gpma, y_train_gpma, y_test_gpma = train_test_split(data_gpma, target_gpma, test_size=0.3, random_state=42)\n",
    "    result = {}\n",
    "    reg = []\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for iteration in iter_gpma:\n",
    "        for lr in lr_gpma:\n",
    "            W_gpma = eval_model(X_train_gpma.T, y_train_gpma, iteration, lr)[1]\n",
    "            W_l1_gpma = eval_model_l1(X_train_gpma.T, y_train_gpma, iteration, lr)\n",
    "            W_l2_gpma = eval_model_l2(X_train_gpma.T, y_train_gpma, iteration, lr)\n",
    "            \n",
    "            pred_train_gpma = calc_pred(W_gpma, X_train_gpma.T)\n",
    "            pred_test_gpma = calc_pred(W_gpma, X_test_gpma.T)\n",
    "            pred_l1_train_gpma = calc_pred(W_l1_gpma, X_train_gpma.T)\n",
    "            pred_l1_test_gpma = calc_pred(W_l1_gpma, X_test_gpma.T)\n",
    "            pred_l2_train_gpma = calc_pred(W_l2_gpma, X_train_gpma.T)\n",
    "            pred_l2_test_gpma = calc_pred(W_l2_gpma, X_test_gpma.T)\n",
    "            \n",
    "            result[f'reg:{iteration}:{lr}'] = [calc_accuracy(pred_train_gpma, y_train_gpma), calc_accuracy(pred_test_gpma, y_test_gpma)]\n",
    "            result[f'L1:{iteration}:{lr}'] = [calc_accuracy(pred_l1_train_gpma, y_train_gpma), calc_accuracy(pred_l1_test_gpma, y_test_gpma)]\n",
    "            result[f'L2:{iteration}:{lr}'] = [calc_accuracy(pred_l2_train_gpma, y_train_gpma), calc_accuracy(pred_l2_test_gpma, y_test_gpma)]\n",
    "    \n",
    "    for params, metrics in result.items():\n",
    "        if 'reg' in params:\n",
    "            if result[params][0] != 100:\n",
    "                reg.append(result[params])\n",
    "        elif 'L1' in params:\n",
    "            if result[params][0] != 100:\n",
    "                l1.append(result[params])\n",
    "        elif 'L2' in params:\n",
    "            if result[params][0] != 100:\n",
    "                l2.append(result[params])\n",
    "    return [get_key(result, max_score(reg)), get_key(result, max_score(l1)), get_key(result, max_score(l2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['reg:50000:0.0001', 'L1:25000:0.01', 'L2:25000:0.01']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выполняется около 20 минут\n",
    "# iteration_2 = [25000 + i * 25000 for i in range(10)]\n",
    "# lr_2 = [10 ** -i for i in range(2, 8)]\n",
    "\n",
    "# best_params_2 = get_params_max_acc(X, y, iteration_2, lr_2)\n",
    "# best_params_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['reg:50000:0.0001', 'L1:25000:0.01', 'L2:25000:0.01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_iter = int(best_params_2[0].split(':')[1])\n",
    "best_reg_lr = float(best_params_2[0].split(':')[2])\n",
    "best_l1_iter = int(best_params_2[1].split(':')[1])\n",
    "best_l1_lr = float(best_params_2[1].split(':')[2])\n",
    "best_l2_iter = int(best_params_2[2].split(':')[1])\n",
    "best_l2_lr = float(best_params_2[2].split(':')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    }
   ],
   "source": [
    "W3_train = eval_model(X_train.T, y_train, best_reg_iter, best_reg_lr)[1]\n",
    "W3_l1 = eval_model_l1(X_train.T, y_train, best_l1_iter, best_l1_lr)\n",
    "W3_l2 = eval_model_l2(X_train.T, y_train, best_l2_iter, best_l2_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2adc72866560>:2: RuntimeWarning: overflow encountered in exp\n",
      "  res = 1 / (1 + np.exp(-z_sig))\n"
     ]
    }
   ],
   "source": [
    "y3_pred_train = calc_pred(W3_train, X_train.T)\n",
    "y3_pred_test = calc_pred(W3_train, X_test.T)\n",
    "y3_pred_train_l1 = calc_pred(W3_l1, X_train.T)\n",
    "y3_pred_test_l1 = calc_pred(W3_l1, X_test.T)\n",
    "y3_pred_train_l2 = calc_pred(W3_l2, X_train.T)\n",
    "y3_pred_test_l2 = calc_pred(W3_l2, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train3 = calc_accuracy(y3_pred_train, y_train)\n",
    "accuracy_test3 = calc_accuracy(y3_pred_test, y_test)\n",
    "accuracy_train_l13 = calc_accuracy(y3_pred_train_l1, y_train)\n",
    "accuracy_test_l13 = calc_accuracy(y3_pred_test_l1, y_test)\n",
    "accuracy_train_l23 = calc_accuracy(y3_pred_train_l2, y_train)\n",
    "accuracy_test_l23 = calc_accuracy(y3_pred_test_l2, y_test)\n",
    "\n",
    "error_matrix_train3 = calc_error_matrix(y3_pred_train, y_train)\n",
    "error_matrix_test3 = calc_error_matrix(y3_pred_test, y_test)\n",
    "error_matrix_train_l13 = calc_error_matrix(y3_pred_train_l1, y_train)\n",
    "error_matrix_test_l13 = calc_error_matrix(y3_pred_test_l1, y_test)\n",
    "error_matrix_train_l23 = calc_error_matrix(y3_pred_train_l2, y_train)\n",
    "error_matrix_test_l23 = calc_error_matrix(y3_pred_test_l2, y_test)\n",
    "\n",
    "\n",
    "precision_train3 = calc_precision(error_matrix_train3)\n",
    "precision_test3 = calc_precision(error_matrix_test3)\n",
    "precision_train_l13 = calc_precision(error_matrix_train_l13)\n",
    "precision_test_l13 = calc_precision(error_matrix_test_l13)\n",
    "precision_train_l23 = calc_precision(error_matrix_train_l23)\n",
    "precision_test_l23 = calc_precision(error_matrix_test_l23)\n",
    "\n",
    "recall_train3 = calc_recall(error_matrix_train3)\n",
    "recall_test3 = calc_recall(error_matrix_test3)\n",
    "recall_train_l13 = calc_recall(error_matrix_train_l13)\n",
    "recall_test_l13 = calc_recall(error_matrix_test_l13)\n",
    "recall_train_l23 = calc_recall(error_matrix_train_l23)\n",
    "recall_test_l23 = calc_recall(error_matrix_test_l23)\n",
    "\n",
    "f1_score_train3 = calc_f1(error_matrix_train3)\n",
    "f1_score_test3 = calc_f1(error_matrix_test3)\n",
    "f1_score_train_l13 = calc_f1(error_matrix_train_l13)\n",
    "f1_score_test_l13 = calc_f1(error_matrix_test_l13)\n",
    "f1_score_train_l23 = calc_f1(error_matrix_train_l23)\n",
    "f1_score_test_l23 = calc_f1(error_matrix_test_l23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_acc: 91.4286\t\tTest_acc: 63.3333\t\tTrain_L1_acc: 50.0000\t\tTest_L1_acc: 53.3333\t\tTrain_L2_acc: 51.4286\t\tTest_L2_acc: 60.0000\n",
      "\n",
      "Train_prec: 0.8611\t\tTest_prec: 0.6875\t\tTrain_L1_prec: 0.4615\t\tTest_L1_prec: 0.6154\t\tTrain_L2_prec: 0.4737\t\tTest_L2_prec: 0.6667\n",
      "\n",
      "Train_rec: 0.9688\t\tTest_rec: 0.6471\t\tTrain_L1_rec: 0.5625\t\tTest_L1_rec: 0.4706\t\tTrain_L2_rec: 0.5625\t\tTest_L2_rec: 0.5882\n",
      "\n",
      "Train_f1: 0.9118\t\tTest_f1: 0.6667\t\t\tTrain_L1_f1: 0.5070\t\tTest_L1_f1: 0.5333\t\tTrain_L2_f1: 0.5143\t\tTest_L2_f1: 0.6250\n",
      "\n",
      "Train_err_mat:\t\tTest_err_mat:\t\t\tTrain_L1_err_mat:\t\tTest_L1_err_mat:\t\tTrain_L2_err_mat:\t\tTest_L2_err_mat:\n",
      "[31  5]\t\t\t\t[11  5]\t\t\t\t[18 21]\t\t\t\t[8 5]\t\t\t\t[18 20]\t\t\t\t[10  5]\n",
      "[ 1 33]\t\t\t\t[6 8]\t\t\t\t[14 17]\t\t\t\t[9 8]\t\t\t\t[14 18]\t\t\t\t[7 8]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train_acc: {accuracy_train3:.4f}\\t\\tTest_acc: {accuracy_test3:.4f}\\t\\tTrain_L1_acc: {accuracy_train_l13:.4f}\\t\\tTest_L1_acc: {accuracy_test_l13:.4f}\\t\\tTrain_L2_acc: {accuracy_train_l23:.4f}\\t\\tTest_L2_acc: {accuracy_test_l23:.4f}\\n\\nTrain_prec: {precision_train3:.4f}\\t\\tTest_prec: {precision_test3:.4f}\\t\\tTrain_L1_prec: {precision_train_l13:.4f}\\t\\tTest_L1_prec: {precision_test_l13:.4f}\\t\\tTrain_L2_prec: {precision_train_l23:.4f}\\t\\tTest_L2_prec: {precision_test_l23:.4f}\\n\\nTrain_rec: {recall_train3:.4f}\\t\\tTest_rec: {recall_test3:.4f}\\t\\tTrain_L1_rec: {recall_train_l13:.4f}\\t\\tTest_L1_rec: {recall_test_l13:.4f}\\t\\tTrain_L2_rec: {recall_train_l23:.4f}\\t\\tTest_L2_rec: {recall_test_l23:.4f}\\n\\nTrain_f1: {f1_score_train3:.4f}\\t\\tTest_f1: {f1_score_test3:.4f}\\t\\t\\tTrain_L1_f1: {f1_score_train_l13:.4f}\\t\\tTest_L1_f1: {f1_score_test_l13:.4f}\\t\\tTrain_L2_f1: {f1_score_train_l23:.4f}\\t\\tTest_L2_f1: {f1_score_test_l23:.4f}\\n\\nTrain_err_mat:\\t\\tTest_err_mat:\\t\\t\\tTrain_L1_err_mat:\\t\\tTest_L1_err_mat:\\t\\tTrain_L2_err_mat:\\t\\tTest_L2_err_mat:\\n{error_matrix_train3[0]}\\t\\t\\t\\t{error_matrix_test3[0]}\\t\\t\\t\\t{error_matrix_train_l13[0]}\\t\\t\\t\\t{error_matrix_test_l13[0]}\\t\\t\\t\\t{error_matrix_train_l23[0]}\\t\\t\\t\\t{error_matrix_test_l23[0]}\\n{error_matrix_train3[1]}\\t\\t\\t\\t{error_matrix_test3[1]}\\t\\t\\t\\t{error_matrix_train_l13[1]}\\t\\t\\t\\t{error_matrix_test_l13[1]}\\t\\t\\t\\t{error_matrix_train_l23[1]}\\t\\t\\t\\t{error_matrix_test_l23[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качастве вывода можно сказать, что хотя модель не улучшила свою точность, она обучилась лучше и на валидационном датасете показала бы лучший результат, так как мы уменьшили ее переобученность. Если перебрать функцию max_score, то можно выцепить параметры для обычной модели с более приближенными друг к другу точностями около 0.6, там есть такой вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
